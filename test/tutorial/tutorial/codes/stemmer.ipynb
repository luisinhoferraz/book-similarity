{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /Users/luisricardoferraz/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('rslp')\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count number of characters in each string\n",
    "def countCharactersInEachString(df, column):\n",
    "    charactersCount = []\n",
    "    for synopsis in df[column]:\n",
    "        charactersCount.append(len(str(synopsis)))\n",
    "    return charactersCount\n",
    "\n",
    "#Count number of words in each string\n",
    "def countWordsInEachString(df, column):\n",
    "    wordsCount = []\n",
    "    for synopsis in df[column]:\n",
    "        words = word_tokenize(str(synopsis))\n",
    "        wordsCount.append(len(words))\n",
    "    return wordsCount\n",
    "\n",
    "#Extract some basic statistics about synopsis\n",
    "def extractBasicStatisticsAboutSynopsis(arrayOfSizes):\n",
    "    synopsisLength = np.array(arrayOfSizes)\n",
    "    basicStatistics = \"\\t\"   \n",
    "    basicStatistics += \"Arithmetic Mean: \" + str(np.mean(synopsisLength)) + \"\\n\\t\"\n",
    "    basicStatistics += \"Median: \" + str(np.median(synopsisLength)) + \"\\n\\t\"\n",
    "    basicStatistics += \"Highest Value: \" + str(np.max(synopsisLength)) + \"\\n\\t\"\n",
    "    basicStatistics += \"Lowest Value: \" + str(np.min(synopsisLength)) + \"\\n\\t\"\n",
    "    basicStatistics += \"Mid-range: \" + str((np.max(synopsisLength)-np.min(synopsisLength))/2) + \"\\n\\t\"\n",
    "    basicStatistics += \"Variance: \" + str(np.var(synopsisLength,ddof=1)) + \"\\n\\t\"\n",
    "    basicStatistics += \"Standard Deviation: \" + str(np.std(synopsisLength,ddof=1)) + \"\\n\\t\"\n",
    "    return basicStatistics\n",
    "\n",
    "def extractPercentilesAboutSynopsis(arrayOfSizes):\n",
    "    synopsisLength = np.array(arrayOfSizes)\n",
    "    percentiles = \"Percentiles: \" + \"\\n\\t\"\n",
    "    count = 0.5\n",
    "    while count <= 100:\n",
    "        percentiles += \"Percentile \" + str(count) + \": \" + str(np.percentile(arrayOfSizes,count)) + \"\\n\\t\"\n",
    "        count += 0.5\n",
    "    return percentiles\n",
    "\n",
    "#Extract some statistics about this Dataset\n",
    "def extractStatisticsFromSynopsis(dataframe, title, column):\n",
    "    log = title + \"\\n\\n\"\n",
    "    log += \"Shape of Dataset: \" + str(dataframe.shape[0]) + \" rows and \" + str(dataframe.shape[1]) + \" columns\" + \"\\n\\n\"\n",
    "    log += \"Statistics of Synopsis Length (Characters):\" + \"\\n\"\n",
    "    charactersCount = countCharactersInEachString(dataframe, column)\n",
    "    log += extractBasicStatisticsAboutSynopsis(charactersCount) + \"\\n\"\n",
    "    log += extractPercentilesAboutSynopsis(charactersCount) + \"\\n\"\n",
    "    log += \"Statistics of Synopsis Length (Words):\" + \"\\n\"\n",
    "    wordsCount = countWordsInEachString(dataframe, column)\n",
    "    log += extractBasicStatisticsAboutSynopsis(wordsCount) + \"\\n\"\n",
    "    log += extractPercentilesAboutSynopsis(wordsCount) + \"\\n\"\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = RSLPStemmer()\n",
    "def applyStemmingOnSynopsis(text):\n",
    "    stringAfterStemming = []\n",
    "    for token in word_tokenize(text):\n",
    "        stringAfterStemming.append(st.stem(token))\n",
    "    return \" \".join(stringAfterStemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = '/Users/luisricardoferraz/book-similarity/test/tutorial/tutorial/spiders/synopsis-preprocessing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import CSV file to a DataFrame\n",
    "df = pd.read_csv(filePath+'dataSetComPosTaggingDepoisDaRemocaoDeStopwords.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmedSynopsis'] = df['synopsisWithoutStopwords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmedSynopsis'] = [applyStemmingOnSynopsis(text) for text in df['stemmedSynopsis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(filePath+'dataSetDepoisDoStemming.csv')\n",
    "with open(filePath+'logDataSetDepoisDoStemming.txt','w') as log:\n",
    "    log.write(extractStatisticsFromSynopsis(df, \"Statistics of Dataset - Stemming Applied to Synopsis\", 'stemmedSynopsis'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import CSV file to a DataFrame\n",
    "df = pd.read_csv(filePath+'dataSetDepoisDoStemming.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jov garot brasil curs ingl exteri poder mei itiner passei estud torvel emoÃ§ astr ascens cinem passei intens poder mund celebr glamour ideal import capaz romanc holofot'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stemmedSynopsis'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
