{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define where's the CSV file\n",
    "filePath = 'C:/Users/LuisRicardoFerraz/Documents/personal/projects/book-similarity/test/tutorial/tutorial/spiders/dataset-clean/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import CSV file to a DataFrame\n",
    "df = pd.read_csv(filePath+'datasetSemDuplicatas.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count number of characters in each string\n",
    "def countCharactersInEachString():\n",
    "    charactersCount = []\n",
    "    for synopsis in df['sinopse']:\n",
    "        charactersCount.append(len(str(synopsis)))\n",
    "    return charactersCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count number of words in each string\n",
    "def countWordsInEachString():\n",
    "    wordsCount = []\n",
    "    for synopsis in df['sinopse']:\n",
    "        words = word_tokenize(str(synopsis))\n",
    "        wordsCount.append(len(words))\n",
    "    return wordsCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract some basic statistics about synopsis\n",
    "def extractBasicStatisticsAboutSynopsis(arrayOfSizes):\n",
    "    synopsisLength = np.array(arrayOfSizes)\n",
    "    basicStatistics = \"\\t\"   \n",
    "    basicStatistics += \"Arithmetic Mean: \" + str(np.mean(synopsisLength)) + \"\\n\\t\"\n",
    "    basicStatistics += \"Median: \" + str(np.median(synopsisLength)) + \"\\n\\t\"\n",
    "    basicStatistics += \"Highest Value: \" + str(np.max(synopsisLength)) + \"\\n\\t\"\n",
    "    basicStatistics += \"Lowest Value: \" + str(np.min(synopsisLength)) + \"\\n\\t\"\n",
    "    basicStatistics += \"Mid-range: \" + str((np.max(synopsisLength)-np.min(synopsisLength))/2) + \"\\n\\t\"\n",
    "    basicStatistics += \"Variance: \" + str(np.var(synopsisLength,ddof=1)) + \"\\n\\t\"\n",
    "    basicStatistics += \"Standard Deviation: \" + str(np.std(synopsisLength,ddof=1)) + \"\\n\\t\"\n",
    "    return basicStatistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPercentilesAboutSynopsis(arrayOfSizes):\n",
    "    synopsisLength = np.array(arrayOfSizes)\n",
    "    percentiles = \"Percentiles: \" + \"\\n\\t\"\n",
    "    count = 0.5\n",
    "    while count <= 100:\n",
    "        percentiles += \"Percentile \" + str(count) + \": \" + str(np.percentile(arrayOfSizes,count)) + \"\\n\\t\"\n",
    "        count += 0.5\n",
    "    return percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract some statistics about this Dataset\n",
    "def extractStatisticsFromSynopsis(title):\n",
    "    log = title + \"\\n\\n\"\n",
    "    log += \"Shape of Dataset: \" + str(df.shape[0]) + \" rows and \" + str(df.shape[1]) + \" columns\" + \"\\n\\n\"\n",
    "    log += \"Statistics of Synopsis Length (Characters):\" + \"\\n\"\n",
    "    charactersCount = countCharactersInEachString()\n",
    "    log += extractBasicStatisticsAboutSynopsis(charactersCount) + \"\\n\"\n",
    "    log += extractPercentilesAboutSynopsis(charactersCount) + \"\\n\"\n",
    "    log += \"Statistics of Synopsis Length (Words):\" + \"\\n\"\n",
    "    wordsCount = countWordsInEachString()\n",
    "    log += extractBasicStatisticsAboutSynopsis(wordsCount) + \"\\n\"\n",
    "    log += extractPercentilesAboutSynopsis(wordsCount) + \"\\n\"\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        uma jovem garota brasileira resolve se aventur...\n",
       "1        \"resgate\" foi a primeira palavra que ouvi quan...\n",
       "2        cage: substantivo: cela, prisão.  verbo: prend...\n",
       "3        feyre has returned to the spring court, determ...\n",
       "4        quebrado. irritado. abandonado. era assim que ...\n",
       "5        uma distopia atual, próxima dos dias de hoje, ...\n",
       "6        as histórias de contos de fadas que as criança...\n",
       "7        maitê passos é uma garota linda, de dezessete ...\n",
       "8        existe uma forma de leveza e de graça no simpl...\n",
       "9        um thriller sobre a luta secreta entre o bem e...\n",
       "10       as crônicas de gelo e fogo. jon snow, daenerys...\n",
       "11       duke é um homem simples com uma vida modesta, ...\n",
       "12       o oitavo volume de wild cards injeta ainda mai...\n",
       "13       diana prince, mais conhecida como mulher-marav...\n",
       "14       na são paulo do início do século xx, a jovem g...\n",
       "15       antes de se tornar a mulher-maravilha, ela era...\n",
       "16       podemos até não viver no paraíso, mas passamos...\n",
       "17       henry cavanaugh, duque de torquil, anseia por ...\n",
       "18       viviane acaba de perder o pai. com a mãe em de...\n",
       "19       nas primeiras horas do dia 16 de dezembro de 1...\n",
       "20       escrito pelo biógrafo oficial de churchill, o ...\n",
       "21       lizzie bennet é uma jovem estudante de comunic...\n",
       "22       ainda recém-casado, o conde tristan deixou sua...\n",
       "23       autoras best-seller do usa today.  melodia do ...\n",
       "24       sterling é uma cidadezinha comum do interior, ...\n",
       "25       o passado de mirabelle está envolto em segredo...\n",
       "26       uma receita apaixonante!  pegue uma dose de ma...\n",
       "27       na pequena ilha de thisby, poucos cavaleiros s...\n",
       "28       livro em formato de bolso e com ilustrações de...\n",
       "29       união de sentimentos – anna cleary cate summer...\n",
       "                               ...                        \n",
       "10344    é 1969 no lower east side de nova york e os ru...\n",
       "10345    este livro é a história dos inúmeros e imprová...\n",
       "10346    encontrando gobi é o relato milagroso de dion ...\n",
       "10347    quando os pais de cameron post morrem em um ac...\n",
       "10348    altares ruíram e templos se perderam nas areia...\n",
       "10349    um unicórnio, um menino e o vento, juntos em u...\n",
       "10350    de revoltas populares a golpes militares, de g...\n",
       "10351    newt, tina, queenie e jacob, os amados heróis ...\n",
       "10352    cora é escrava em uma plantação de algodão da ...\n",
       "10353    você conhece o tasty: o popular canal de culin...\n",
       "10354    em tempos difíceis, há uma urgência de entende...\n",
       "10355    neste livro, o premiado autor ilan brenman apr...\n",
       "10356    o conto de beren e lúthien foi, ou tornou-se, ...\n",
       "10357    nova edição do guinness world records, o mais ...\n",
       "10358    guerra, amor e vida se unem neste drama profun...\n",
       "10359    bella, uma linda cadelinha vira-lata, adotou l...\n",
       "10360    antes do holocausto e da segunda guerra mundia...\n",
       "10361    você já sabe tudo sobre as bff girls? não? ent...\n",
       "10362    não adianta se enganar: o ano só começa mesmo ...\n",
       "10363    \"quando adam st. james colocou os olhos na doc...\n",
       "10364    'um grande barulho ecoou ao redor do mundo, tr...\n",
       "10365    ramon amorim cresceu na pequena cidade de ando...\n",
       "10366    neste livro, o conhecido escritor ilan brenman...\n",
       "10367    o dr. oscar serrallach é um especialista neoze...\n",
       "10368    a vida de rhys cole sempre girou em torno do h...\n",
       "10369    nunca era um grito de vitória, mas sim de dor....\n",
       "10370    sawyer quer ter a própria vida. finn quer esqu...\n",
       "10371    o amor que o finn e eu compartilhamos é do tip...\n",
       "10372    james bradley sabia o que imprensa era capaz d...\n",
       "10373    neste livro você será envolvido por temas emoc...\n",
       "Name: sinopse, Length: 10374, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sinopse'] = [sinopse.lower() for sinopse in df['sinopse']]\n",
    "df['sinopse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = 'C:/Users/LuisRicardoFerraz/Documents/personal/projects/book-similarity/test/tutorial/tutorial/spiders/synopsis-cleaning/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filePath+'logDatasetComSinopsesEmMinusculas.txt','w') as log:\n",
    "    log.write(extractStatisticsFromSynopsis(\"Statistics of Dataset - Lower case on synopsis\"))\n",
    "df.to_csv(filePath+'dataSetComSinopsesEmMinusculas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import CSV file to a DataFrame\n",
    "df = pd.read_csv(filePath+'dataSetComSinopsesEmMinusculas.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findInSynopsis(array_tmp, pattern):\n",
    "    for text in array_tmp:\n",
    "        occurrences = re.findall(pattern,text)\n",
    "        if len(occurrences) > 0:\n",
    "            print(occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover URLs, hashtags e tags de marcação\n",
    "# colocar um espaço entre pontos e palavras\n",
    "# remover números\n",
    "# remover pontuação e caracteres especiais (travessão, reticências, aspas francesas)\n",
    "# tokenizar\n",
    "\n",
    "def removeUrlsFromSynopsis(text):\n",
    "    text = re.sub('http\\S+','',text)\n",
    "    text = re.sub('www.\\S+','',text)\n",
    "    return text\n",
    "\n",
    "def removeHashtagsFromSynopsis(text):\n",
    "    text = re.sub('#\\w+','',text)\n",
    "    return text\n",
    "\n",
    "def removeProfileTagsFromSynopsis(text):\n",
    "    text = re.sub('@\\w+','',text)\n",
    "    return text\n",
    "\n",
    "def insertSpaceBetweenDotsAndWords(text):\n",
    "    occurrences = re.findall('\\.\\w+',text)\n",
    "    for string in occurrences:\n",
    "        fixing = string.replace('.','. ')\n",
    "        text = text.replace(string,fixing)\n",
    "    return text\n",
    "\n",
    "def removeNumbersFromSynopsis(text):\n",
    "    text = re.sub('[0-9]+','',text)\n",
    "    return text\n",
    "\n",
    "def removeSpecialCharacters(text):\n",
    "    text = re.sub('[－⸻\\^\\?\\.֊`º︱﹣®‘%\\\\―〝´~゠\\־⹀〞\\$〰\\)»;/ª}&︲•<:«°\"|!’§⸚｢\\+\\]‑⸺=《\\*(–,_—”…\\-᐀⸗〜>\\[‐᠆@‒“﹘·\\'{]+',' ', text)\n",
    "    return text\n",
    "\n",
    "def removeDieresisFromSynopsis(text):\n",
    "    text = re.sub('[Ä]','A',text)\n",
    "    text = re.sub('[Ë]','E',text)\n",
    "    text = re.sub('[Ï]','I',text)\n",
    "    text = re.sub('[Ö]','O',text)\n",
    "    text = re.sub('[Ü]','U',text)\n",
    "    text = re.sub('[ä]','a',text)\n",
    "    text = re.sub('[ë]','e',text)\n",
    "    text = re.sub('[ï]','i',text)\n",
    "    text = re.sub('[ö]','o',text)\n",
    "    text = re.sub('[ü]','u',text)\n",
    "    return text\n",
    "\n",
    "def removeExtraSpacesFromSynopsis(text):\n",
    "    text = re.sub('[ ]+',' ',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10299, 27)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['sinopse'].map(len) > 140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filePath+'logDatasetComSinopsesDeTamanhoFiltrado.txt','w') as log:\n",
    "    log.write(extractStatisticsFromSynopsis(\"Statistics of Dataset - Minimum Length For Synopsis\"))\n",
    "df.to_csv(filePath+'dataSetComSinopsesDeTamanhoFiltrado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import CSV file to a DataFrame\n",
    "df = pd.read_csv(filePath+'dataSetComSinopsesDeTamanhoFiltrado.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sinopse'] = [removeUrlsFromSynopsis(text) for text in df['sinopse']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filePath+'logDatasetComSinopsesSemUrls.txt','w') as log:\n",
    "    log.write(extractStatisticsFromSynopsis(\"Statistics of Dataset - Synopsis without URLs\"))\n",
    "df.to_csv(filePath+'dataSetComSinopsesSemUrls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import CSV file to a DataFrame\n",
    "df = pd.read_csv(filePath+'dataSetComSinopsesSemUrls.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sinopse'] = [removeHashtagsFromSynopsis(text) for text in df['sinopse']]\n",
    "with open(filePath+'logDatasetComSinopsesSemHashtags.txt','w') as log:\n",
    "    log.write(extractStatisticsFromSynopsis(\"Statistics of Dataset - Synopsis without Hashtags\"))\n",
    "df.to_csv(filePath+'dataSetComSinopsesSemHashtags.csv')\n",
    "#Import CSV file to a DataFrame\n",
    "df = pd.read_csv(filePath+'dataSetComSinopsesSemHashtags.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sinopse'] = [removeProfileTagsFromSynopsis(text) for text in df['sinopse']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filePath+'logDatasetComSinopsesSemProfileTags.txt','w') as log:\n",
    "    log.write(extractStatisticsFromSynopsis(\"Statistics of Dataset - Synopsis without Profile Tags\"))\n",
    "df.to_csv(filePath+'dataSetComSinopsesSemProfileTags.csv')\n",
    "#Import CSV file to a DataFrame\n",
    "df = pd.read_csv(filePath+'dataSetComSinopsesSemProfileTags.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sinopse'] = [insertSpaceBetweenDotsAndWords(text) for text in df['sinopse']]\n",
    "df['sinopse'] = [removeNumbersFromSynopsis(text) for text in df['sinopse']]\n",
    "with open(filePath+'logDatasetComSinopsesSemNumeros.txt','w') as log:\n",
    "    log.write(extractStatisticsFromSynopsis(\"Statistics of Dataset - Synopsis without Numbers\"))\n",
    "df.to_csv(filePath+'dataSetComSinopsesSemNumeros.csv')\n",
    "#Import CSV file to a DataFrame\n",
    "df = pd.read_csv(filePath+'dataSetComSinopsesSemNumeros.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sinopse'] = [removeSpecialCharacters(text) for text in df['sinopse']]\n",
    "df['sinopse'] = [removeDieresisFromSynopsis(text) for text in df['sinopse']]\n",
    "with open(filePath+'logDatasetComSinopsesSemCaracteresEspeciais.txt','w') as log:\n",
    "    log.write(extractStatisticsFromSynopsis(\"Statistics of Dataset - Synopsis without Special Characters\"))\n",
    "df.to_csv(filePath+'dataSetComSinopsesSemCaracteresEspeciais.csv')\n",
    "#Import CSV file to a DataFrame\n",
    "df = pd.read_csv(filePath+'dataSetComSinopsesSemCaracteresEspeciais.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sinopse'] = [removeExtraSpacesFromSynopsis(text) for text in df['sinopse']]\n",
    "with open(filePath+'logDatasetComSinopsesSemExcessoDeEspacos.txt','w') as log:\n",
    "    log.write(extractStatisticsFromSynopsis(\"Statistics of Dataset - Synopsis Trimmed\"))\n",
    "df.to_csv(filePath+'dataSetComSinopsesSemExcessoDeEspacos.csv')\n",
    "#Import CSV file to a DataFrame\n",
    "df = pd.read_csv(filePath+'dataSetComSinopsesSemExcessoDeEspacos.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = 'C:/Users/LuisRicardoFerraz/Documents/personal/projects/book-similarity/test/tutorial/tutorial/spiders/synopsis-preprocessing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filePath+'logDatasetComSinopsesLimpas.txt','w') as log:\n",
    "    log.write(extractStatisticsFromSynopsis(\"Statistics of Dataset - Synopsis Cleaned\"))\n",
    "df.to_csv(filePath+'dataSetComSinopsesLimpas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import CSV file to a DataFrame\n",
    "df = pd.read_csv(filePath+'dataSetComSinopsesLimpas.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are problems with «» and ÄËÏÖÜäëïöü and the size of the synopsis and ´ ª ° extra spaces ‘ ?? § and UTF-8 (must convert to string first) and · ®\n",
    "#Limit for PortService-Br analysis: 7000 characters in each synopsis\n",
    "def identifyUnknownWords(text):\n",
    "    log = ''\n",
    "    try:\n",
    "        payload = {'texto': str(text)}\n",
    "        response = requests.get('http://portservice.pythonanywhere.com/analise/morfossintatica/freeling', params=payload).json()\n",
    "        string = []\n",
    "        for word in response:\n",
    "            string.append('' if word['lemma'] != '<unknown>' else word['token'])\n",
    "        log += str(\" \".join(set(string))) + \"\\n\"\n",
    "    except:\n",
    "        print(text)\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a log to identify words which PortService-Br doesn't recognize\n",
    "#If the word is from Portuguese and is mispelled, or it is not from Portuguese language, it will be shown in the .txt file.\n",
    "#If there's anything wrong with the API request, the synopsis will be shown here.\n",
    "#with open(filePath+'logDatasetComPalavrasDesconhecidasIdentificadas.txt','w', encoding='utf-8') as log:\n",
    "#    for text in df['sinopse']:\n",
    "#        log.write(identifyUnknownWords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code helps on identifying words which have the same letter repeated 3+ times\n",
    "#They are part of not-in-vocabulary words\n",
    "#There are only few words that match this case, so the best I can do is to ignore them and remove them along with the stopwords\n",
    "#array_tmp = df['sinopse']\n",
    "#for letter in ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']:\n",
    "#    findInSynopsis(array_tmp, '\\S+['+letter+']{3,}\\S+')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
