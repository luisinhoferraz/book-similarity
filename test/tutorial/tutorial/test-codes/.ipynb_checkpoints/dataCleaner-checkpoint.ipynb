{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define where's the CSV file\n",
    "filePath = 'C:/Users/LuisRicardoFerraz/Documents/personal/projects/book-similarity/test/tutorial/tutorial/spiders/dataset-clean/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import CSV file to a DataFrame\n",
    "df = pd.read_csv(filePath+'dataSetInicial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        \\r\\n                           Uma jovem garot...\n",
       "1        \\r\\n                           \"RESGATE\" Foi a...\n",
       "2        \\r\\n                           Cage: substanti...\n",
       "3        \\r\\n                           Feyre has retur...\n",
       "4        \\r\\n                           A doença que cr...\n",
       "5        \\r\\n                           Quebrado. Irrit...\n",
       "6        \\r\\n                           Uma distopia at...\n",
       "7        \\r\\n                           As histórias de...\n",
       "8        \\r\\n                           Maitê Passos é ...\n",
       "9        \\r\\n                           Dandelion guard...\n",
       "10       \\r\\n                           Existe uma form...\n",
       "11       \\r\\n                           Com clareza e i...\n",
       "12       \\r\\n                           Um thriller sob...\n",
       "13       \\r\\n                           As Crônicas de ...\n",
       "14       \\r\\n                           \"Se meu livro A...\n",
       "15       \\r\\n                           This courageous...\n",
       "16       \\r\\n                           Duke é um homem...\n",
       "17       \\r\\n                           O oitavo volume...\n",
       "18       \\r\\n                           Diana Prince, m...\n",
       "19       \\r\\n                           Na São Paulo do...\n",
       "20       \\r\\n                           Antes de se tor...\n",
       "21       \\r\\n                           Podemos até não...\n",
       "22       \\r\\n                           Henry Cavanaugh...\n",
       "23       \\r\\n                           Viviane acaba d...\n",
       "24       \\r\\n                           Nas primeiras h...\n",
       "25       \\r\\n                           Escrito pelo bi...\n",
       "26       \\r\\n                           Lizzie Bennet é...\n",
       "27       \\r\\n                           Segundo livro d...\n",
       "28       \\r\\n                           Ainda recém-cas...\n",
       "29       \\r\\n                           Autoras best-se...\n",
       "                               ...                        \n",
       "13617    \\r\\n                           Um unicórnio, u...\n",
       "13618    \\r\\n                           De revoltas pop...\n",
       "13619    \\r\\n                           Newt, Tina, Que...\n",
       "13620    \\r\\n                           Cora é escrava ...\n",
       "13621    \\r\\n                           Você conhece o ...\n",
       "13622    \\r\\n                           Em tempos difíc...\n",
       "13623    \\r\\n                           Neste livro, o ...\n",
       "13624    \\r\\n                           O conto de Bere...\n",
       "13625    \\r\\n                           Nova edição do ...\n",
       "13626    \\r\\n                           1895: Londres e...\n",
       "13627    \\r\\n                           Guerra, amor e ...\n",
       "13628    \\r\\n                           Bella, uma lind...\n",
       "13629    \\r\\n                           Antes do Holoca...\n",
       "13630    \\r\\n                           On the first an...\n",
       "13631    \\r\\n                           Você já sabe tu...\n",
       "13632    \\r\\n                           Esta é a minha ...\n",
       "13633    \\r\\n                           Não adianta se ...\n",
       "13634    \\r\\n                           \"Quando Adam St...\n",
       "13635    \\r\\n                           'Um grande baru...\n",
       "13636    \\r\\n                           Ramon Amorim cr...\n",
       "13637    \\r\\n                           Neste livro, o ...\n",
       "13638    \\r\\n                           O Dr. Oscar Ser...\n",
       "13639    \\r\\n                           “Uma universida...\n",
       "13640    \\r\\n                           A vida de Rhys ...\n",
       "13641    \\r\\n                           Nunca era um gr...\n",
       "13642    \\r\\n                           Sawyer quer ter...\n",
       "13643    \\r\\n                           O amor que o Fi...\n",
       "13644    \\r\\n                           James Bradley s...\n",
       "13645    \\r\\n                           Dizem que o bat...\n",
       "13646    \\r\\n                           Neste livro voc...\n",
       "Name: sinopse, Length: 13647, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sinopse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count number of characters in each string\n",
    "def countCharactersInEachString():\n",
    "    charactersCount = []\n",
    "    for synopsis in df['sinopse']:\n",
    "        charactersCount.append(len(str(synopsis)))\n",
    "    return charactersCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count number of words in each string\n",
    "def countWordsInEachString():\n",
    "    wordsCount = []\n",
    "    for synopsis in df['sinopse']:\n",
    "        words = word_tokenize(str(synopsis))\n",
    "        wordsCount.append(len(words))\n",
    "    return wordsCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract some basic statistics about synopsis\n",
    "def extractBasicStatisticsAboutSynopsis(arrayOfSizes):\n",
    "    synopsisLength = np.array(arrayOfSizes)\n",
    "    basicStatistics = \"\\t\"   \n",
    "    basicStatistics += \"Arithmetic Mean: \" + str(np.mean(synopsisLength)) + \"\\n\\t\"\n",
    "    basicStatistics += \"Median: \" + str(np.median(synopsisLength)) + \"\\n\\t\"\n",
    "    basicStatistics += \"Highest Value: \" + str(np.max(synopsisLength)) + \"\\n\\t\"\n",
    "    basicStatistics += \"Lowest Value: \" + str(np.min(synopsisLength)) + \"\\n\\t\"\n",
    "    basicStatistics += \"Mid-range: \" + str((np.max(synopsisLength)-np.min(synopsisLength))/2) + \"\\n\\t\"\n",
    "    basicStatistics += \"Variance: \" + str(np.var(synopsisLength,ddof=1)) + \"\\n\\t\"\n",
    "    basicStatistics += \"Standard Deviation: \" + str(np.std(synopsisLength,ddof=1)) + \"\\n\\t\"\n",
    "    return basicStatistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPercentilesAboutSynopsis(arrayOfSizes):\n",
    "    synopsisLength = np.array(arrayOfSizes)\n",
    "    percentiles = \"Percentiles: \" + \"\\n\\t\"\n",
    "    count = 0.5\n",
    "    while count <= 100:\n",
    "        percentiles += \"Percentile \" + str(count) + \": \" + str(np.percentile(arrayOfSizes,count)) + \"\\n\\t\"\n",
    "        count += 0.5\n",
    "    return percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract types of dataset columns\n",
    "def extractTypeOfAllColumns():\n",
    "    log = \"\\t\"\n",
    "    for column in df:\n",
    "        log += str(column) + \": \" + str(df.dtypes[column]) + \"\\n\\t\"\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tisbn-10: 0.0\n",
      "\tisbn-13: 0.0\n",
      "\ttitulo: 0.0\n",
      "\tautor: 0.0\n",
      "\teditora: 0.0\n",
      "\tano: 0.0\n",
      "\tpaginas: 0.0\n",
      "\tidioma: 0.0\n",
      "\tleram: 0.0\n",
      "\tlendo: 0.0\n",
      "\tqueremLer: 0.0\n",
      "\trelendo: 0.0\n",
      "\tabandonos: 0.0\n",
      "\tresenhas: 0.0\n",
      "\tnota: 0.0\n",
      "\tfavoritos: 0.0\n",
      "\tdesejados: 0.0\n",
      "\ttrocam: 0.0\n",
      "\tavaliaram: 0.0\n",
      "\tcincoEstrelas: 0.0\n",
      "\tquatroEstrelas: 0.0\n",
      "\ttresEstrelas: 0.0\n",
      "\tduasEstrelas: 0.0\n",
      "\tumaEstrela: 0.0\n",
      "\tavaliacoesHomens: 0.0\n",
      "\tavaliacoesMulheres: 0.0\n",
      "\tsinopse: 0.0\n",
      "\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Count the null fields in each column\n",
    "def extractNullFieldsInAllColumns():\n",
    "    log = \"\\t\"\n",
    "    for column in df:\n",
    "        array = [nullValue for nullValue in df[column] if str(nullValue) == 'nan']\n",
    "        log += str(column)+\": \"+str(len(array)*100/df.shape[0]) + \"\\n\\t\"\n",
    "    log += \"\\n\"\n",
    "    return log\n",
    "print(extractNullFieldsInAllColumns())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract some statistics about this Dataset\n",
    "def extractStatisticsFromDataset(title):\n",
    "    log = title + \"\\n\\n\"\n",
    "    log += \"Shape of Dataset: \" + str(df.shape[0]) + \" rows and \" + str(df.shape[1]) + \" columns\" + \"\\n\\n\"\n",
    "    log += \"Type of each column: \" + \"\\n\"\n",
    "    log += extractTypeOfAllColumns()\n",
    "    log += \"\\n\"\n",
    "    log += \"Percentage of Null Values per column:\" + \"\\n\"\n",
    "    log += extractNullFieldsInAllColumns()\n",
    "    log += \"Statistics of Synopsis Length (Characters):\" + \"\\n\"\n",
    "    charactersCount = countCharactersInEachString()\n",
    "    log += extractBasicStatisticsAboutSynopsis(charactersCount) + \"\\n\"\n",
    "    log += extractPercentilesAboutSynopsis(charactersCount) + \"\\n\"\n",
    "    log += \"Statistics of Synopsis Length (Words):\" + \"\\n\"\n",
    "    wordsCount = countWordsInEachString()\n",
    "    log += extractBasicStatisticsAboutSynopsis(wordsCount) + \"\\n\"\n",
    "    log += extractPercentilesAboutSynopsis(wordsCount) + \"\\n\"\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/LuisRicardoFerraz/Documents/personal/projects/book-similarity/test/tutorial/tutorial/spiders/logDatasetInicial.txt','w') as log:\n",
    "    log.write(extractStatisticsFromDataset(\"Statistics of Dataset - Created recently\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['subtitulo','generos','tags'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Remove null fields from a list of columns in DataFrame\n",
    "df = df.dropna(axis=0,how='any',subset=['isbn-10','isbn-13','titulo','autor','editora','ano','paginas','leram','lendo','queremLer','relendo','abandonos','resenhas','nota','favoritos','desejados','trocam','avaliaram','cincoEstrelas','quatroEstrelas','tresEstrelas','duasEstrelas','umaEstrela','avaliacoesHomens','avaliacoesMulheres','sinopse'],inplace=False)\n",
    "df = df.dropna(axis=0,how='any',subset=['sinopse'],inplace=False)\n",
    "df = df.dropna(axis=0,how='any',subset=['ano'],inplace=False)\n",
    "df = df.dropna(axis=0,how='any',subset=['sinopse'],inplace=False)\n",
    "df = df.dropna(axis=0,how='any',subset=['ano'],inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filePath+'logDatasetSemValoresNulos.txt','w') as log:\n",
    "    log.write(extractStatisticsFromDataset(\"Statistics of Dataset - Without null values\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(filePath+'datasetSemCamposNulos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filePath+'datasetSemCamposNulos.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove spaces excess\n",
    "for string in df.columns:\n",
    "    df[string] = [str(item).strip() for item in df[string]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filePath+'logDatasetSemEspacos.txt','w') as log:\n",
    "    log.write(extractStatisticsFromDataset(\"Statistics of Dataset - Without spaces excess\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(filePath+'datasetSemEspacos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filePath+'datasetSemEspacos.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0,how='any',subset=['sinopse'],inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePercentage(value):\n",
    "    return int(value.replace('%',''))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ano in df['ano']:\n",
    "    if str(ano) == 'nan':\n",
    "        print(ano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['ano'].map(len) == 9]\n",
    "df['ano'] = [ano.replace('Ano: ', '') for ano in df['ano']]\n",
    "df = df[df['idioma'].map(len) == 17]\n",
    "df['idioma'] = [idioma.replace('Idioma: ', '') for idioma in df['idioma']]\n",
    "df['paginas'] = [pagina.replace('Páginas: ', '') for pagina in df['paginas']]\n",
    "for column in ['favoritos','desejados','trocam','avaliaram']:\n",
    "    df[column] = [re.search('[0-9]+',value).group() for value in df[column]]\n",
    "for column in ['cincoEstrelas','quatroEstrelas','tresEstrelas','duasEstrelas','umaEstrela','avaliacoesHomens','avaliacoesMulheres']:\n",
    "    df[column] = [removePercentage(value) for value in df[column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filePath+'logDatasetComOutrosCamposNormalizados.txt','w') as log:\n",
    "    log.write(extractStatisticsFromDataset(\"Statistics of Dataset - All columns but Synopsis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(filePath+'datasetComOutrosCamposNormalizados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeColumnTypes():\n",
    "    for column in ['isbn-10', 'isbn-13', 'titulo', 'autor', 'editora', 'idioma', 'sinopse']:\n",
    "        df[column] = df[column].astype(str)\n",
    "    for column in ['ano', 'paginas', 'leram', 'lendo', 'queremLer', 'relendo', 'abandonos', 'resenhas', 'favoritos', 'desejados', 'trocam', 'avaliaram']:\n",
    "        df[column] = df[column].astype(int)\n",
    "    for column in ['nota', 'cincoEstrelas', 'quatroEstrelas', 'tresEstrelas', 'duasEstrelas', 'umaEstrela', 'avaliacoesHomens', 'avaliacoesMulheres']:\n",
    "        df[column] = df[column].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filePath+'datasetComOutrosCamposNormalizados.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizeColumnTypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['avaliaram'] <= df['leram']]\n",
    "df = df[df['favoritos'] <= df['leram']]\n",
    "df = df[df['relendo'] <= df['leram']]\n",
    "df = df[df['resenhas'] <= df['leram']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filePath+'logDatasetSemOutliers.txt','w') as log:\n",
    "    log.write(extractStatisticsFromDataset(\"Statistics of Dataset - Outliers removed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(filePath+'datasetSemOutliers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filePath+'datasetSemOutliers.csv')\n",
    "df = df.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11039, 27)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates from DataFrame\n",
    "df = df.drop_duplicates(subset=['isbn-10','isbn-13'],keep='first',inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filePath+'logDatasetSemDuplicatas.txt','w') as log:\n",
    "    log.write(extractStatisticsFromDataset(\"Statistics of Dataset - Duplicates removed\"))\n",
    "df.to_csv(filePath+'datasetSemDuplicatas.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
